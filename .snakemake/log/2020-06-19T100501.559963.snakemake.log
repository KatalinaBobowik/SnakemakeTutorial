Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	map_reads
	1	sort
	2

[Fri Jun 19 10:05:01 2020]
rule map_reads:
    input: data/genome.fa, data/samples/B.fastq
    output: mapped/B.bam
    jobid: 1
    wildcards: sample=B

Activating conda environment: /home/kbobowik/snakemake-tutorial/.snakemake/conda/1e5f4063
[Fri Jun 19 10:05:03 2020]
Finished job 1.
1 of 2 steps (50%) done

[Fri Jun 19 10:05:03 2020]
rule sort:
    input: mapped/B.bam
    output: mapped/B.sorted.bam
    jobid: 0
    wildcards: sample=B

Activating conda environment: /home/kbobowik/snakemake-tutorial/.snakemake/conda/1e5f4063
[Fri Jun 19 10:05:04 2020]
Finished job 0.
2 of 2 steps (100%) done
Complete log: /home/kbobowik/snakemake-tutorial/.snakemake/log/2020-06-19T100501.559963.snakemake.log
